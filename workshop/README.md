# DEATHCon Workshop: Human vs AI Detection Engineering Competition

## üéØ Workshop Overview

**Title:** "PERSEPTOR: AI-Powered Detection Engineering in Action"  
**Duration:** 60 minutes  
**Format:** Live Human vs AI Competition  
**Audience:** 512+ Detection Engineers and Threat Hunters  

### Workshop Description

Experience the future of detection engineering through an exciting live competition between human security experts and PERSEPTOR AI. Watch as both teams analyze the same threat intelligence report and race to generate the most effective detection rules in real-time.

## üöÄ Competition Format

### The Challenge
- **Hidden Threat Report:** A real threat intelligence report revealed only when the competition starts
- **Time Limit:** 30-60 minutes to generate detection rules
- **Live Streaming:** Participants' screens are shared so the audience can follow the process
- **Lab Environment:** Pre-loaded with events to test generated rules

### Scoring Criteria
- **Rule Quality:** Valid syntax and proper structure
- **Coverage:** Detection of multiple attack techniques
- **Accuracy:** Low false positives, high true positives
- **Innovation:** Creative detection approaches
- **MITRE ATT&CK Mapping:** Proper technique identification

## üõ†Ô∏è PERSEPTOR AI Capabilities

### Core Features Demonstrated
1. **Automated Threat Analysis**
   - Real-time URL-based threat report analysis
   - OCR processing for images and documents
   - Intelligent content extraction and summarization

2. **Detection Rule Generation**
   - **Sigma Rules:** Comprehensive YAML-based detection rules
   - **YARA Rules:** Pattern-based malware detection signatures
   - **SIEM Queries:** Splunk, QRadar, and Elastic queries

3. **Intelligence Extraction**
   - **IoCs:** IPs, domains, URLs, file hashes, registry keys
   - **TTPs:** MITRE ATT&CK technique mapping
   - **Threat Actors:** Attribution and profiling
   - **Tools & Malware:** Identification and classification

4. **Quality Assurance**
   - Rule validation and syntax checking
   - Confidence scoring for generated rules
   - Global Sigma rule matching
   - False positive analysis

## üìã Workshop Agenda

### Pre-Competition (10 minutes)
- Introduction to PERSEPTOR platform
- Competition rules and scoring system
- Lab environment overview
- Participant introductions

### Competition Phase (45 minutes)
- **Minute 0:** Threat report revealed to all participants
- **Minutes 1-45:** Live rule generation and development
- **Real-time Updates:** Leaderboard and progress tracking
- **Audience Engagement:** Q&A and commentary

### Post-Competition (5 minutes)
- Results announcement and analysis
- Discussion of AI vs Human approaches
- Lessons learned and best practices
- Q&A session

## üèóÔ∏è Technical Setup

### Infrastructure Requirements
- **Hosted PERSEPTOR Instance:** Pre-configured for workshop
- **Lab Environment:** Events and test data ready
- **Streaming Setup:** Screen sharing and live commentary
- **Scoring System:** Real-time rule validation and scoring

### Cost Considerations
- **LLM Usage:** ~$1.50 per participant session
- **Infrastructure:** Cloud hosting for 512+ participants
- **Lab Environment:** Pre-configured detection testing

## üìä Expected Outcomes

### Learning Objectives
1. **AI-Assisted Detection Engineering**
   - Understand how AI can accelerate threat intelligence operationalization
   - Learn to leverage AI for detection rule generation
   - Compare AI vs human approaches to detection engineering

2. **Practical Skills**
   - Real-time threat analysis techniques
   - Detection rule validation and testing
   - MITRE ATT&CK mapping best practices

3. **Industry Insights**
   - Future of AI in cybersecurity
   - Automation vs human expertise
   - Scaling detection engineering processes

### Deliverables
- **Generated Detection Rules:** Sigma and YARA rules from both teams
- **Analysis Reports:** Comprehensive threat intelligence summaries
- **Performance Metrics:** Speed, accuracy, and quality comparisons
- **Best Practices Guide:** Lessons learned and recommendations

## üéÆ Competition Rules

### For Human Participants
- Use any tools and techniques available
- Generate rules manually or with assistance tools
- Document reasoning and methodology
- Test rules in lab environment

### For AI Participant (PERSEPTOR)
- Automated analysis of threat report
- AI-generated detection rules
- Real-time confidence scoring
- Integration with lab testing environment

### Validation Criteria
- **Syntax Validation:** Proper rule format and structure
- **Logic Validation:** Sound detection logic
- **Coverage Validation:** Comprehensive threat coverage
- **Performance Validation:** Test against lab events

## üîß Lab Environment

### Pre-loaded Events
- **Process Creation Events:** Windows event logs
- **Network Traffic:** Packet captures and flow data
- **File System Activity:** File creation and modification
- **Registry Changes:** Registry key modifications
- **Command Line Activity:** PowerShell and command execution

### Testing Framework
- **Rule Validation:** Automatic syntax and logic checking
- **Performance Testing:** Rule execution speed and resource usage
- **False Positive Analysis:** Testing against benign activity
- **Coverage Analysis:** Detection effectiveness measurement

## üìà Success Metrics

### Competition Metrics
- **Rule Count:** Number of rules generated
- **Rule Quality:** Validation scores and effectiveness
- **Speed:** Time to generate first rule
- **Coverage:** MITRE ATT&CK technique coverage
- **Innovation:** Creative detection approaches

### Workshop Metrics
- **Audience Engagement:** Participation and interaction
- **Knowledge Transfer:** Learning objectives achieved
- **Practical Application:** Skills demonstrated
- **Future Adoption:** Interest in AI-assisted detection

## üéØ Target Audience

### Primary Audience
- **Detection Engineers:** Creating and maintaining detection rules
- **Threat Hunters:** Proactive threat identification
- **SOC Analysts:** Security operations center personnel
- **Incident Responders:** Handling security incidents

### Secondary Audience
- **Security Architects:** Designing security frameworks
- **CISO/CSO:** Strategic security leadership
- **Researchers:** Cybersecurity research community
- **Students:** Learning detection engineering

## üåü Unique Value Proposition

### Why This Workshop Matters
1. **Real-world Application:** Live demonstration of AI in detection engineering
2. **Competitive Learning:** Engaging format with immediate feedback
3. **Practical Skills:** Hands-on experience with modern tools
4. **Future-focused:** Understanding AI's role in cybersecurity

### Innovation Highlights
- **First-of-its-kind:** Human vs AI competition format
- **Live Streaming:** Real-time audience engagement
- **Comprehensive Platform:** End-to-end detection engineering workflow
- **Quality Focus:** Emphasis on rule validation and effectiveness

## üìû Contact Information

**Workshop Leader:** Aytek AYTEMUR  
**Email:** [Your Email]  
**LinkedIn:** [Your LinkedIn]  
**GitHub:** [Your GitHub]  

**Platform:** PERSEPTOR - AI-Driven Detection Engineering Platform  
**Website:** [Your Website]  
**Documentation:** [Your Documentation]  

---

## üöÄ Getting Started

### For Workshop Participants
1. **Pre-workshop Preparation:**
   - Review MITRE ATT&CK framework
   - Familiarize with Sigma and YARA rule formats
   - Prepare development environment

2. **During the Workshop:**
   - Follow live stream and participate in chat
   - Ask questions and provide feedback
   - Take notes on techniques and approaches

3. **Post-workshop:**
   - Access generated rules and analysis
   - Review best practices and lessons learned
   - Connect with other participants

### For Lab Environment Access
- **URL:** [Workshop Lab URL]
- **Credentials:** Provided during workshop
- **Duration:** Available for 2+ months post-workshop
- **Support:** Discord channel for assistance

---

*This workshop is part of DEATHCon 2025 - Detection Engineering and Threat Hunting Conference*
